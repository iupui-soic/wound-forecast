{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d68123d0",
   "metadata": {},
   "source": [
    "# Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f6312c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pmdarima\n",
      "  Downloading pmdarima-2.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl (1.9 MB)\n",
      "     |████████████████████████████████| 1.9 MB 7.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: pandas>=0.19 in /home/jupyter-apaddo/.local/lib/python3.9/site-packages (from pmdarima) (2.0.3)\n",
      "Requirement already satisfied: setuptools!=50.0.0,>=38.6.0 in /opt/tljh/user/lib/python3.9/site-packages (from pmdarima) (58.2.0)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /home/jupyter-apaddo/.local/lib/python3.9/site-packages (from pmdarima) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /home/jupyter-apaddo/.local/lib/python3.9/site-packages (from pmdarima) (1.3.0)\n",
      "Requirement already satisfied: urllib3 in /opt/tljh/user/lib/python3.9/site-packages (from pmdarima) (1.26.7)\n",
      "Requirement already satisfied: statsmodels>=0.13.2 in /home/jupyter-apaddo/.local/lib/python3.9/site-packages (from pmdarima) (0.14.0)\n",
      "Collecting Cython!=0.29.18,!=0.29.31,>=0.29\n",
      "  Downloading Cython-3.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "     |████████████████████████████████| 3.6 MB 146.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /home/jupyter-apaddo/.local/lib/python3.9/site-packages (from pmdarima) (1.11.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/jupyter-apaddo/.local/lib/python3.9/site-packages (from pmdarima) (1.3.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/jupyter-apaddo/.local/lib/python3.9/site-packages (from pandas>=0.19->pmdarima) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/tljh/user/lib/python3.9/site-packages (from pandas>=0.19->pmdarima) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/tljh/user/lib/python3.9/site-packages (from pandas>=0.19->pmdarima) (2022.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/jupyter-apaddo/.local/lib/python3.9/site-packages (from scikit-learn>=0.22->pmdarima) (3.2.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /home/jupyter-apaddo/.local/lib/python3.9/site-packages (from statsmodels>=0.13.2->pmdarima) (0.5.3)\n",
      "Requirement already satisfied: packaging>=21.3 in /opt/tljh/user/lib/python3.9/site-packages (from statsmodels>=0.13.2->pmdarima) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/tljh/user/lib/python3.9/site-packages (from packaging>=21.3->statsmodels>=0.13.2->pmdarima) (3.0.9)\n",
      "Requirement already satisfied: six in /opt/tljh/user/lib/python3.9/site-packages (from patsy>=0.5.2->statsmodels>=0.13.2->pmdarima) (1.16.0)\n",
      "Installing collected packages: Cython, pmdarima\n",
      "\u001b[33m  WARNING: The scripts cygdb, cython and cythonize are installed in '/home/jupyter-apaddo/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed Cython-3.0.0 pmdarima-2.0.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pmdarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49701d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import lagrange\n",
    "from scipy.interpolate import CubicSpline, InterpolatedUnivariateSpline, Akima1DInterpolator\n",
    "from datetime import datetime, timedelta\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "import statsmodels.api as sm\n",
    "#from datetime import timedelta\n",
    "#import datetime\n",
    "#import fbprophet\n",
    "#from matplotlib import pyplot\n",
    "from pandas import to_datetime\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "#from fbprophet import Prophet\n",
    "#from pmdarima.arima import auto_arima\n",
    "#import pmdarima\n",
    "from scipy import interpolate\n",
    "#from fbprophet import Prophet\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "import plotly.graph_objs as go\n",
    "import sklearn.model_selection\n",
    "from scipy import stats\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow import keras\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.interpolate import CubicSpline as CS\n",
    "from statistics import mean\n",
    "import math\n",
    "from pmdarima.arima import auto_arima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e94c0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_for=pd.read_csv(\"6_df_interpolated_for_forecasting_may22.csv\")\n",
    "# df_for=df_for.drop([\"Unnamed: 0\"],axis=1)\n",
    "# df_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "feb3329d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Area</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Ethinicity</th>\n",
       "      <th>Wound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-10-26</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-10-27</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290115</th>\n",
       "      <td>1290115</td>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2.7064</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>17884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290116</th>\n",
       "      <td>1290116</td>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2.7064</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>17884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290117</th>\n",
       "      <td>1290117</td>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>2.7064</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>17884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290118</th>\n",
       "      <td>1290118</td>\n",
       "      <td>2023-01-08</td>\n",
       "      <td>2.7064</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>17884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290119</th>\n",
       "      <td>1290119</td>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>2.7064</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>17884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1290120 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0        Date    Area Gender   Race    Ethinicity  Wound\n",
       "0                 0  2016-10-26  4.0000      M  White  Non-Hispanic      1\n",
       "1                 1  2016-10-27  4.0000      M  White  Non-Hispanic      1\n",
       "2                 2  2016-10-28  4.0000      M  White  Non-Hispanic      1\n",
       "3                 3  2016-10-29  4.0000      M  White  Non-Hispanic      1\n",
       "4                 4  2016-10-30  4.0000      M  White  Non-Hispanic      1\n",
       "...             ...         ...     ...    ...    ...           ...    ...\n",
       "1290115     1290115  2023-01-05  2.7064      F  White  Non-Hispanic  17884\n",
       "1290116     1290116  2023-01-06  2.7064      F  White  Non-Hispanic  17884\n",
       "1290117     1290117  2023-01-07  2.7064      F  White  Non-Hispanic  17884\n",
       "1290118     1290118  2023-01-08  2.7064      F  White  Non-Hispanic  17884\n",
       "1290119     1290119  2023-01-09  2.7064      F  White  Non-Hispanic  17884\n",
       "\n",
       "[1290120 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for=pd.read_csv(\"6_df_interpolated_for_forecasting_aug10.csv\")\n",
    "#df_for=df_for.drop([\"Unnamed: 0\"],axis=1)\n",
    "df_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3dbfdc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_for.to_csv(\"df_merged_for_forecasting_may01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fb364a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #function for model input in ARIMA only\n",
    "# def make_input_for_arima(dff):\n",
    "#     dff_interpolated = dff\n",
    "#     train_set_number=int(0.85*len(dff_interpolated))\n",
    "#     test_set_number=len(dff_interpolated)-train_set_number\n",
    "\n",
    "#     #Creating train and test set \n",
    "#     train=dff_interpolated[0:train_set_number] \n",
    "#     test=dff_interpolated[train_set_number:]\n",
    "\n",
    "#     #to get the future dates for forecasting\n",
    "#     date_specific=test.loc[:,'Date']\n",
    "#     ff=date_specific.reset_index(drop=True)\n",
    "#     #print(ff)\n",
    "#     import datetime\n",
    "#     for aa in range(0,14,1):    #range is given till 14 days as we are forecasting for 14 days or 2 weeks\n",
    "#         u = datetime.datetime.strptime(str(ff[len(ff)-1]),\"%Y-%m-%d\")\n",
    "#         d = datetime.timedelta(days=1)\n",
    "#         t = u + d     #adds one new day with the dataframe\n",
    "#         tt =t.strftime(\"%Y-%m-%d\")   #creates that added new date from datetime object to string\n",
    "#         dict={'Date':[tt]}\n",
    "#         dff_2 = pd.DataFrame(dict)\n",
    "#         test = test.append(dff_2, ignore_index = True)\n",
    "#         date_specific=test.loc[:,'Date']\n",
    "#         ff=date_specific.reset_index(drop=True)\n",
    "\n",
    "#     #Aggregating the dataset at daily level\n",
    "#     dff_interpolated.Timestamp = pd.to_datetime(dff_interpolated.Date,format='%Y-%m-%d %H:%M:%S') \n",
    "#     dff_interpolated.index = dff_interpolated.Timestamp \n",
    "#     dff_interpolated = dff_interpolated.resample('D').mean()\n",
    "#     train.Timestamp = pd.to_datetime(train.Date,format='%Y-%m-%d %H:%M:%S') \n",
    "#     train.index = train.Timestamp \n",
    "#     train = train.resample('D').mean()\n",
    "#     test.Timestamp = pd.to_datetime(test.Date,format='%Y-%m-%d %H:%M:%S') \n",
    "#     test.index = test.Timestamp \n",
    "#     test = test.resample('D').mean()\n",
    "#     return (test, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95aeb9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_for_arima(df):    \n",
    "    #display(df)\n",
    "    df=df.reset_index()\n",
    "    total_n=df.shape[0]\n",
    "    n=math.ceil(0.15*total_n)\n",
    "    dff=pd.concat([df, df.tail(n), df.tail(n)]).drop_duplicates(keep=False)\n",
    "    #display(test)\n",
    "    #display(dff)\n",
    "    sample_row=dff.sample(1)\n",
    "    a=int(sample_row.index.values)\n",
    "    b=int(sample_row.index.values)+n\n",
    "    #print(a)\n",
    "    #print(b)\n",
    "    test=df[a:b]\n",
    "    train=pd.concat([df, test, test]).drop_duplicates(keep=False)\n",
    "    # #display(train)\n",
    "    return (test,train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3f48976",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_holtwinters(test, train):\n",
    "    #fit1 = sm.tsa.statespace.SARIMAX(train.Area, order=(2, 1, 4),seasonal_order=(0,1,1,7),initialization='approximate_diffuse').fit()\n",
    "    fit1 = ExponentialSmoothing(np.asarray(train['Area']) ,seasonal_periods=2 ,trend='add', seasonal='add').fit()\n",
    "\n",
    "    y_hat_avg = test.copy()\n",
    "    y_hat_avg['Holtwinters'] = fit1.forecast(len(test))\n",
    "    #print(y_hat_avg['ARIMA'])\n",
    "    plt.figure(figsize=(16,8))\n",
    "    plt.plot( train['Area'], label='Train')\n",
    "    plt.plot(test['Area'], label='Test')\n",
    "    plt.plot(y_hat_avg['Holtwinters'], label='Holtwinters')\n",
    "    plt.legend(loc='best')\n",
    "    #plt.axhline(0)\n",
    "    plt.grid()\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Wound Area')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Accuracy measure of the model (to be done next)\n",
    "    forecast=y_hat_avg.Holtwinters\n",
    "    actual=test.Area\n",
    "    training_series=train.Area\n",
    "    testing_series=test.Area\n",
    "    prediction_series= y_hat_avg.Holtwinters\n",
    "\n",
    "\n",
    "\n",
    "    mape = np.mean(np.abs(forecast - actual)/np.abs(actual))  # MAPE\n",
    "    me = np.mean(forecast - actual)             # ME\n",
    "    mae = np.mean(np.abs(forecast - actual))    # MAE\n",
    "    mpe = np.mean((forecast - actual)/actual)   # MPE\n",
    "    rmse = np.mean((forecast - actual)**2)**.5  # RMSE\n",
    "     #as R-square value does not for forecasted value and actual value because forecasted values are 14 more than actual values, thus I am taking only the forecasted values minusing the last 14 values of the forecasted dataframe.\n",
    "    # df = df.iloc[:-2]\n",
    "    #forecast_without_last14=forecast.iloc[:-14]\n",
    "    #actual_without_nan=actual.dropna()\n",
    "    corr = np.corrcoef(forecast, actual)[0,1]   # corr\n",
    "    #corr= np.corrcoef(forecast_without_last14,actual_without_nan)[0,1]\n",
    "    r_square= corr**2\n",
    "#     mins = np.amin(np.hstack([forecast[:,None], \n",
    "#                               actual[:,None]]), axis=1)\n",
    "#     maxs = np.amax(np.hstack([forecast[:,None], \n",
    "#                               actual[:,None]]), axis=1)\n",
    "#     minmax = 1 - np.mean(mins/maxs)             # minmax\n",
    "    #acf1 = acf(fc-test)[1]  # ACF1\n",
    "\n",
    "    n = training_series.shape[0]\n",
    "    d = np.abs(  np.diff( training_series) ).sum()/(n-1)\n",
    "    errors = np.abs(testing_series - prediction_series )\n",
    "    mase=errors.mean()/d\n",
    "\n",
    "    #print(\"For Subject ID:\", list[i])\n",
    "#     print(\"MASE:\",mase)\n",
    "#     print(\"MAPE:\",mape)\n",
    "#     print(\"ME:\",me)\n",
    "#     print(\"MAE:\",mae)\n",
    "#     print(\"MPE:\",mpe)\n",
    "#     print(\"RMSE:\",rmse)\n",
    "#     print(\"CORR:\",corr)\n",
    "#     print(\"R-SQUARE\",r_square)\n",
    "#     print(\"MINMAX:\",minmax)\n",
    "    return (rmse, mase, r_square)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb6f34f",
   "metadata": {},
   "source": [
    "## Counting the number of wounds from patients from different categories and running ARIMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "08340989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_for_f=df_for.query(\"Gender=='F'\")\n",
    "# df_for_m=df_for.query(\"Gender=='M'\")\n",
    "\n",
    "# df_for_White=df_for.query(\"Race=='White'\")\n",
    "# df_for_Black=df_for.query(\"Race=='Black'\")\n",
    "# df_for_ASKU=df_for.query(\"Race=='ASKU'\")\n",
    "# df_for_Asian=df_for.query(\"Race=='Asian'\")\n",
    "# df_for_American Indian or Alaska Native=df_for.query(\"Race=='American Indian or Alaska Native'\")\n",
    "# df_for_Native Hawaiian or Other Pacific Islander=df_for.query(\"Race=='Native Hawaiian or Other Pacific Islander'\")\n",
    "# df_for_Other=df_for.query(\"Race=='Other'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aaa4ec7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_female_r_square=[]\n",
    "# list_male_r_square=[]\n",
    "# list_white_r_square=[]\n",
    "# list_black_r_square=[]\n",
    "# list_asku_r_square=[]\n",
    "# list_asian_r_square=[]\n",
    "# list_americanindian_r_square=[]\n",
    "# list_nativehawaiian_r_square=[]\n",
    "# list_other_r_square=[]\n",
    "# list_hispanic_r_square=[]\n",
    "# list_nonhispanic_r_square=[]\n",
    "# list_patientdeclined_r_square=[]\n",
    "\n",
    "\n",
    "# list_female_rmse=[]\n",
    "# list_male_rmse=[]\n",
    "# list_white_rmse=[]\n",
    "# list_black_rmse=[]\n",
    "# list_asku_rmse=[]\n",
    "# list_asian_rmse=[]\n",
    "# list_americanindian_rmse=[]\n",
    "# list_nativehawaiian_rmse=[]\n",
    "# list_other_rmse=[]\n",
    "# list_hispanic_rmse=[]\n",
    "# list_nonhispanic_rmse=[]\n",
    "# list_patientdeclined_rmse=[]\n",
    "\n",
    "\n",
    "# list_female_mase=[]\n",
    "# list_male_mase=[]\n",
    "# list_white_mase=[]\n",
    "# list_black_mase=[]\n",
    "# list_asku_mase=[]\n",
    "# list_asian_mase=[]\n",
    "# list_americanindian_mase=[]\n",
    "# list_nativehawaiian_mase=[]\n",
    "# list_other_mase=[]\n",
    "# list_hispanic_mase=[]\n",
    "# list_nonhispanic_mase=[]\n",
    "# list_patientdeclined_mase=[]\n",
    "\n",
    "\n",
    "# list_female_nan=0\n",
    "# list_male_nan=0\n",
    "# list_white_nan=0\n",
    "# list_black_nan=0\n",
    "# list_asku_nan=0\n",
    "# list_asian_nan=0\n",
    "# list_americanindian_nan=0\n",
    "# list_nativehawaiian_nan=0\n",
    "# list_other_nan=0\n",
    "# list_hispanic_nan=0\n",
    "# list_nonhispanic_nan=0\n",
    "# list_patientdeclined_nan=0\n",
    "\n",
    "\n",
    "# list_wounds=df_for[\"Wound\"].unique()\n",
    "\n",
    "# for i in range(len(list_wounds)):\n",
    "# #     if i>4:\n",
    "# #         break\n",
    "#     print(\"Wound:\",i+1)\n",
    "#     wound=list_wounds[i]\n",
    "#     df_1=df_for.query(\"Wound==@wound\")\n",
    "#     #display(df)\n",
    "#     df=df_1[[\"Date\",\"Area\"]]\n",
    "#     test,train=make_input_for_arima(df)\n",
    "#     if train.shape[0]>1:\n",
    "#         if train.shape[0]==2 or train.shape[0]==3:\n",
    "#             if len(list(set(train.Area.values.tolist())))>1 & (datetime.strptime(train.reset_index()[\"Date\"][train.shape[0]-1],'%Y-%m-%d')-datetime.strptime(train.reset_index()[\"Date\"][0],'%Y-%m-%d')).days>2 and train[\"Area\"].dropna().shape[0]!=0:\n",
    "            \n",
    "#                 rmse, mase, r_square=model_holtwinters(test, train)\n",
    "\n",
    "#                 if str(r_square)=='nan' or str(r_square)=='inf':\n",
    "\n",
    "#                     #Check gender\n",
    "#                     if df_1[\"Gender\"].unique()[0]=='F':\n",
    "#                         list_female_nan=list_female_nan+1\n",
    "#                     elif df_1[\"Gender\"].unique()[0]=='M':\n",
    "#                         list_male_nan=list_male_nan+1\n",
    "\n",
    "#                     #Check race\n",
    "#                     if df_1[\"Race\"].unique()[0]=='White':\n",
    "#                         list_white_nan=list_white_nan+1\n",
    "#                     elif df_1[\"Race\"].unique()[0]=='Black':\n",
    "#                         list_black_nan=list_black_nan+1\n",
    "#                     if df_1[\"Race\"].unique()[0]=='ASKU':\n",
    "#                         list_asku_nan=list_asku_nan+1\n",
    "#                     if df_1[\"Race\"].unique()[0]=='Asian':\n",
    "#                         list_asian_nan=list_asian_nan+1\n",
    "#                     if df_1[\"Race\"].unique()[0]=='American Indian or Alaska Native':\n",
    "#                         list_americanindian_nan=list_americanindian_nan+1\n",
    "#                     if df_1[\"Race\"].unique()[0]=='Native Hawaiian or Other Pacific Islander':\n",
    "#                         list_nativehawaiian_nan=list_nativehawaiian_nan+1\n",
    "#                     if df_1[\"Race\"].unique()[0]=='Other':\n",
    "#                         list_other_nan=list_other_nan+1\n",
    "\n",
    "#                     #Check ethnicity\n",
    "#                     if df_1[\"Ethinicity\"].unique()[0]=='Hispanic':\n",
    "#                         list_hispanic_nan=list_hispanic_nan+1\n",
    "#                     elif df_1[\"Ethinicity\"].unique()[0]=='Non-Hispanic':\n",
    "#                         list_nonhispanic_nan=list_nonhispanic_nan+1\n",
    "#                     if df_1[\"Ethinicity\"].unique()[0]=='Patient Declined':\n",
    "#                         list_patientdeclined_nan=list_patientdeclined_nan+1\n",
    "\n",
    "#                 else:\n",
    "\n",
    "#                     #Check gender\n",
    "#                     if df_1[\"Gender\"].unique()[0]=='F':\n",
    "#                         list_female_r_square.append(r_square)\n",
    "#                         list_female_rmse.append(rmse)\n",
    "#                         list_female_mase.append(mase)\n",
    "\n",
    "#                     elif df_1[\"Gender\"].unique()[0]=='M':\n",
    "#                         list_male_r_square.append(r_square)\n",
    "#                         list_male_rmse.append(rmse)\n",
    "#                         list_male_mase.append(mase)\n",
    "\n",
    "\n",
    "#                     #Check race\n",
    "#                     if df_1[\"Race\"].unique()[0]=='White':\n",
    "#                         list_white_r_square.append(r_square)\n",
    "#                         list_white_rmse.append(rmse)\n",
    "#                         list_white_mase.append(mase)\n",
    "#                     elif df_1[\"Race\"].unique()[0]=='Black':\n",
    "#                         list_black_r_square.append(r_square)\n",
    "#                         list_black_rmse.append(rmse)\n",
    "#                         list_black_mase.append(mase)\n",
    "#                     if df_1[\"Race\"].unique()[0]=='ASKU':\n",
    "#                         list_asku_r_square.append(r_square)\n",
    "#                         list_asku_rmse.append(rmse)\n",
    "#                         list_asku_mase.append(mase)\n",
    "#                     if df_1[\"Race\"].unique()[0]=='Asian':\n",
    "#                         list_asian_r_square.append(r_square)\n",
    "#                         list_asian_rmse.append(rmse)\n",
    "#                         list_asian_mase.append(mase)\n",
    "#                     if df_1[\"Race\"].unique()[0]=='American Indian or Alaska Native':\n",
    "#                         list_americanindian_r_square.append(r_square)\n",
    "#                         list_americanindian_rmse.append(rmse)\n",
    "#                         list_americanindian_mase.append(mase)\n",
    "#                     if df_1[\"Race\"].unique()[0]=='Native Hawaiian or Other Pacific Islander':\n",
    "#                         list_nativehawaiian_r_square.append(r_square)\n",
    "#                         list_nativehawaiian_rmse.append(rmse)\n",
    "#                         list_nativehawaiian_mase.append(mase)\n",
    "#                     if df_1[\"Race\"].unique()[0]=='Other':\n",
    "#                         list_other_r_square.append(r_square)\n",
    "#                         list_other_rmse.append(rmse)\n",
    "#                         list_other_mase.append(mase)\n",
    "\n",
    "#                     #Check ethnicity\n",
    "#                     if df_1[\"Ethinicity\"].unique()[0]=='Hispanic':\n",
    "#                         list_hispanic_r_square.append(r_square)\n",
    "#                         list_hispanic_rmse.append(rmse)\n",
    "#                         list_hispanic_mase.append(mase)\n",
    "#                     elif df_1[\"Ethinicity\"].unique()[0]=='Non-Hispanic':\n",
    "#                         list_nonhispanic_r_square.append(r_square)\n",
    "#                         list_nonhispanic_rmse.append(rmse)\n",
    "#                         list_nonhispanic_mase.append(mase)\n",
    "#                     if df_1[\"Ethinicity\"].unique()[0]=='Patient Declined':\n",
    "#                         list_patientdeclined_r_square.append(r_square)\n",
    "#                         list_patientdeclined_rmse.append(rmse)\n",
    "#                         list_patientdeclined_mase.append(mase)\n",
    "                    \n",
    "#         if train.shape[0]>3 and train[\"Area\"].dropna().shape[0]!=0:\n",
    "            \n",
    "#             rmse, mase, r_square=model_holtwinters(test, train)\n",
    "\n",
    "#             if str(r_square)=='nan' or str(r_square)=='inf':\n",
    "\n",
    "#                 #Check gender\n",
    "#                 if df_1[\"Gender\"].unique()[0]=='F':\n",
    "#                     list_female_nan=list_female_nan+1\n",
    "#                 elif df_1[\"Gender\"].unique()[0]=='M':\n",
    "#                     list_male_nan=list_male_nan+1\n",
    "\n",
    "#                 #Check race\n",
    "#                 if df_1[\"Race\"].unique()[0]=='White':\n",
    "#                     list_white_nan=list_white_nan+1\n",
    "#                 elif df_1[\"Race\"].unique()[0]=='Black':\n",
    "#                     list_black_nan=list_black_nan+1\n",
    "#                 if df_1[\"Race\"].unique()[0]=='ASKU':\n",
    "#                     list_asku_nan=list_asku_nan+1\n",
    "#                 if df_1[\"Race\"].unique()[0]=='Asian':\n",
    "#                     list_asian_nan=list_asian_nan+1\n",
    "#                 if df_1[\"Race\"].unique()[0]=='American Indian or Alaska Native':\n",
    "#                     list_americanindian_nan=list_americanindian_nan+1\n",
    "#                 if df_1[\"Race\"].unique()[0]=='Native Hawaiian or Other Pacific Islander':\n",
    "#                     list_nativehawaiian_nan=list_nativehawaiian_nan+1\n",
    "#                 if df_1[\"Race\"].unique()[0]=='Other':\n",
    "#                     list_other_nan=list_other_nan+1\n",
    "\n",
    "#                 #Check ethnicity\n",
    "#                 if df_1[\"Ethinicity\"].unique()[0]=='Hispanic':\n",
    "#                     list_hispanic_nan=list_hispanic_nan+1\n",
    "#                 elif df_1[\"Ethinicity\"].unique()[0]=='Non-Hispanic':\n",
    "#                     list_nonhispanic_nan=list_nonhispanic_nan+1\n",
    "#                 if df_1[\"Ethinicity\"].unique()[0]=='Patient Declined':\n",
    "#                     list_patientdeclined_nan=list_patientdeclined_nan+1\n",
    "\n",
    "#             else:\n",
    "\n",
    "#                 #Check gender\n",
    "#                 if df_1[\"Gender\"].unique()[0]=='F':\n",
    "#                     list_female_r_square.append(r_square)\n",
    "#                     list_female_rmse.append(rmse)\n",
    "#                     list_female_mase.append(mase)\n",
    "\n",
    "#                 elif df_1[\"Gender\"].unique()[0]=='M':\n",
    "#                     list_male_r_square.append(r_square)\n",
    "#                     list_male_rmse.append(rmse)\n",
    "#                     list_male_mase.append(mase)\n",
    "\n",
    "\n",
    "#                 #Check race\n",
    "#                 if df_1[\"Race\"].unique()[0]=='White':\n",
    "#                     list_white_r_square.append(r_square)\n",
    "#                     list_white_rmse.append(rmse)\n",
    "#                     list_white_mase.append(mase)\n",
    "#                 elif df_1[\"Race\"].unique()[0]=='Black':\n",
    "#                     list_black_r_square.append(r_square)\n",
    "#                     list_black_rmse.append(rmse)\n",
    "#                     list_black_mase.append(mase)\n",
    "#                 if df_1[\"Race\"].unique()[0]=='ASKU':\n",
    "#                     list_asku_r_square.append(r_square)\n",
    "#                     list_asku_rmse.append(rmse)\n",
    "#                     list_asku_mase.append(mase)\n",
    "#                 if df_1[\"Race\"].unique()[0]=='Asian':\n",
    "#                     list_asian_r_square.append(r_square)\n",
    "#                     list_asian_rmse.append(rmse)\n",
    "#                     list_asian_mase.append(mase)\n",
    "#                 if df_1[\"Race\"].unique()[0]=='American Indian or Alaska Native':\n",
    "#                     list_americanindian_r_square.append(r_square)\n",
    "#                     list_americanindian_rmse.append(rmse)\n",
    "#                     list_americanindian_mase.append(mase)\n",
    "#                 if df_1[\"Race\"].unique()[0]=='Native Hawaiian or Other Pacific Islander':\n",
    "#                     list_nativehawaiian_r_square.append(r_square)\n",
    "#                     list_nativehawaiian_rmse.append(rmse)\n",
    "#                     list_nativehawaiian_mase.append(mase)\n",
    "#                 if df_1[\"Race\"].unique()[0]=='Other':\n",
    "#                     list_other_r_square.append(r_square)\n",
    "#                     list_other_rmse.append(rmse)\n",
    "#                     list_other_mase.append(mase)\n",
    "\n",
    "#                 #Check ethnicity\n",
    "#                 if df_1[\"Ethinicity\"].unique()[0]=='Hispanic':\n",
    "#                     list_hispanic_r_square.append(r_square)\n",
    "#                     list_hispanic_rmse.append(rmse)\n",
    "#                     list_hispanic_mase.append(mase)\n",
    "#                 elif df_1[\"Ethinicity\"].unique()[0]=='Non-Hispanic':\n",
    "#                     list_nonhispanic_r_square.append(r_square)\n",
    "#                     list_nonhispanic_rmse.append(rmse)\n",
    "#                     list_nonhispanic_mase.append(mase)\n",
    "#                 if df_1[\"Ethinicity\"].unique()[0]=='Patient Declined':\n",
    "#                     list_patientdeclined_r_square.append(r_square)\n",
    "#                     list_patientdeclined_rmse.append(rmse)\n",
    "#                     list_patientdeclined_mase.append(mase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46a344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_wounds=df_for[\"Wound\"].unique()\n",
    "\n",
    "result_df=pd.DataFrame(index=np.arange(len(list_wounds)))\n",
    "\n",
    "result_df[\"Wound\"]=np.nan\n",
    "result_df[\"Gender\"]=np.nan\n",
    "result_df[\"Race\"]=np.nan\n",
    "result_df[\"Ethinicity\"]=np.nan\n",
    "result_df[\"RMSE\"]=np.nan\n",
    "result_df[\"MASE\"]=np.nan\n",
    "result_df[\"R-squared\"]=np.nan\n",
    "    \n",
    "\n",
    "for i in range(len(list_wounds)):\n",
    "#     if i>4:\n",
    "#         break\n",
    "    print(\"Wound:\",i+1)\n",
    "    wound=list_wounds[i]\n",
    "    df_1=df_for.query(\"Wound==@wound\")\n",
    "    #display(df_1)\n",
    "    df=df_1[[\"Date\",\"Area\"]]\n",
    "    test,train=make_input_for_arima(df)\n",
    "    \n",
    "    \n",
    "    result_df[\"Wound\"][i]=int(df_1[\"Wound\"].unique()[0])\n",
    "    result_df[\"Gender\"][i]=str(df_1[\"Gender\"].unique()[0])\n",
    "    result_df[\"Race\"][i]=str(df_1[\"Race\"].unique()[0])\n",
    "    result_df[\"Ethinicity\"][i]=str(df_1[\"Ethinicity\"].unique()[0])\n",
    "\n",
    "    if train.shape[0]>1:\n",
    "        if train.shape[0]==2 or train.shape[0]==3:\n",
    "            if len(list(set(train.Area.values.tolist())))>1 & (datetime.strptime(train.reset_index()[\"Date\"][train.shape[0]-1],'%Y-%m-%d')-datetime.strptime(train.reset_index()[\"Date\"][0],'%Y-%m-%d')).days>2 and train[\"Area\"].dropna().shape[0]!=0:\n",
    "            \n",
    "                rmse, mase, r_square=model_holtwinters(test, train)\n",
    "                result_df[\"RMSE\"][i]=rmse\n",
    "                result_df[\"MASE\"][i]=mase\n",
    "                result_df[\"R-squared\"][i]=r_square\n",
    "                \n",
    "        if train.shape[0]>3 and train[\"Area\"].dropna().shape[0]!=0:\n",
    "            \n",
    "            rmse, mase, r_square=model_holtwinters(test, train)\n",
    "            result_df[\"RMSE\"][i]=rmse\n",
    "            result_df[\"MASE\"][i]=mase\n",
    "            result_df[\"R-squared\"][i]=r_square\n",
    "                \n",
    "result_df[\"Wound\"]=result_df[\"Wound\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8674ee3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wound</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Ethinicity</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MASE</th>\n",
       "      <th>R-squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>1.479525</td>\n",
       "      <td>5.066716</td>\n",
       "      <td>0.046923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>1.014797</td>\n",
       "      <td>4.723285</td>\n",
       "      <td>0.927650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>0.185481</td>\n",
       "      <td>7.490611</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>2.328319</td>\n",
       "      <td>6.992540</td>\n",
       "      <td>0.993764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>0.872019</td>\n",
       "      <td>15.624282</td>\n",
       "      <td>0.979899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14913</th>\n",
       "      <td>17877</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>2.596683</td>\n",
       "      <td>16.561704</td>\n",
       "      <td>0.887877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14914</th>\n",
       "      <td>17879</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>0.093146</td>\n",
       "      <td>5.265298</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14915</th>\n",
       "      <td>17880</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>1.795225</td>\n",
       "      <td>5.114129</td>\n",
       "      <td>0.953891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14916</th>\n",
       "      <td>17881</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>13.141264</td>\n",
       "      <td>4.433311</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14917</th>\n",
       "      <td>17884</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14918 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Wound Gender   Race    Ethinicity       RMSE       MASE  R-squared\n",
       "0          1      M  White  Non-Hispanic   1.479525   5.066716   0.046923\n",
       "1          2      M  White  Non-Hispanic   1.014797   4.723285   0.927650\n",
       "2          3      M  White  Non-Hispanic   0.185481   7.490611   1.000000\n",
       "3          5      M  White  Non-Hispanic   2.328319   6.992540   0.993764\n",
       "4          6      M  White  Non-Hispanic   0.872019  15.624282   0.979899\n",
       "...      ...    ...    ...           ...        ...        ...        ...\n",
       "14913  17877      M  White  Non-Hispanic   2.596683  16.561704   0.887877\n",
       "14914  17879      F  White  Non-Hispanic   0.093146   5.265298        NaN\n",
       "14915  17880      F  White  Non-Hispanic   1.795225   5.114129   0.953891\n",
       "14916  17881      M  White  Non-Hispanic  13.141264   4.433311   1.000000\n",
       "14917  17884      F  White  Non-Hispanic   0.000000        NaN        NaN\n",
       "\n",
       "[14918 rows x 7 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d98ec488",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.to_csv(\"Holt_winters_result_Aug24.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a997f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=result_df.dropna()\n",
    "result_df=result_df.replace({np.inf:np.nan})\n",
    "result_df=result_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8780fd9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wound</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Ethinicity</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MASE</th>\n",
       "      <th>R-squared</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>1.479525</td>\n",
       "      <td>5.066716</td>\n",
       "      <td>0.046923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>1.014797</td>\n",
       "      <td>4.723285</td>\n",
       "      <td>0.927650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>0.185481</td>\n",
       "      <td>7.490611</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>2.328319</td>\n",
       "      <td>6.992540</td>\n",
       "      <td>0.993764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>0.872019</td>\n",
       "      <td>15.624282</td>\n",
       "      <td>0.979899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14911</th>\n",
       "      <td>17875</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>0.378447</td>\n",
       "      <td>8.993306</td>\n",
       "      <td>0.996527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14912</th>\n",
       "      <td>17876</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>6.212400</td>\n",
       "      <td>9.657690</td>\n",
       "      <td>0.930276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14913</th>\n",
       "      <td>17877</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>2.596683</td>\n",
       "      <td>16.561704</td>\n",
       "      <td>0.887877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14915</th>\n",
       "      <td>17880</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>1.795225</td>\n",
       "      <td>5.114129</td>\n",
       "      <td>0.953891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14916</th>\n",
       "      <td>17881</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>13.141264</td>\n",
       "      <td>4.433311</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13227 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Wound Gender   Race    Ethinicity       RMSE       MASE  R-squared\n",
       "0          1      M  White  Non-Hispanic   1.479525   5.066716   0.046923\n",
       "1          2      M  White  Non-Hispanic   1.014797   4.723285   0.927650\n",
       "2          3      M  White  Non-Hispanic   0.185481   7.490611   1.000000\n",
       "3          5      M  White  Non-Hispanic   2.328319   6.992540   0.993764\n",
       "4          6      M  White  Non-Hispanic   0.872019  15.624282   0.979899\n",
       "...      ...    ...    ...           ...        ...        ...        ...\n",
       "14911  17875      F  White  Non-Hispanic   0.378447   8.993306   0.996527\n",
       "14912  17876      F  White  Non-Hispanic   6.212400   9.657690   0.930276\n",
       "14913  17877      M  White  Non-Hispanic   2.596683  16.561704   0.887877\n",
       "14915  17880      F  White  Non-Hispanic   1.795225   5.114129   0.953891\n",
       "14916  17881      M  White  Non-Hispanic  13.141264   4.433311   1.000000\n",
       "\n",
       "[13227 rows x 7 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e4e68d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
