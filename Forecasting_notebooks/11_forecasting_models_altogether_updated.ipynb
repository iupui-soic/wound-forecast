{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d68123d0",
   "metadata": {},
   "source": [
    "# Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8fcd347",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pystan==2.19.1.1 convertdate==2.4.0 lunarcalendar==0.0.9 holidays==0.13 fbprophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49701d35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-29 11:04:26.817062: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-29 11:04:26.838781: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-29 11:04:26.839282: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-29 11:04:27.314751: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import lagrange\n",
    "from scipy.interpolate import CubicSpline, InterpolatedUnivariateSpline, Akima1DInterpolator\n",
    "from datetime import datetime, timedelta\n",
    "from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n",
    "import statsmodels.api as sm\n",
    "#from datetime import timedelta\n",
    "#import datetime\n",
    "#import fbprophet\n",
    "#from matplotlib import pyplot\n",
    "from pandas import to_datetime\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "#from fbprophet import Prophet\n",
    "#from pmdarima.arima import auto_arima\n",
    "#import pmdarima\n",
    "from scipy import interpolate\n",
    "#from fbprophet import Prophet\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from tensorflow.keras import Sequential, layers, callbacks\n",
    "from tensorflow.keras.layers import Dense, LSTM, Dropout, GRU, Bidirectional\n",
    "import plotly.graph_objs as go\n",
    "import sklearn.model_selection\n",
    "from scipy import stats\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from tensorflow import keras\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from scipy.interpolate import CubicSpline as CS\n",
    "from statistics import mean\n",
    "import math\n",
    "from fbprophet import Prophet\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Bidirectional\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import tensorflow as tf\n",
    "from statsforecast import StatsForecast\n",
    "from statsforecast.models import AutoARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c283bae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pystan==2.19.1.1 lunarcalendar==0.0.9 holidays==0.13 fbprophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feb3329d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Area</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Race</th>\n",
       "      <th>Ethinicity</th>\n",
       "      <th>Wound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-26</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-27</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-28</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>4.0000</td>\n",
       "      <td>M</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290115</th>\n",
       "      <td>2023-01-05</td>\n",
       "      <td>2.7064</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>17884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290116</th>\n",
       "      <td>2023-01-06</td>\n",
       "      <td>2.7064</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>17884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290117</th>\n",
       "      <td>2023-01-07</td>\n",
       "      <td>2.7064</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>17884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290118</th>\n",
       "      <td>2023-01-08</td>\n",
       "      <td>2.7064</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>17884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290119</th>\n",
       "      <td>2023-01-09</td>\n",
       "      <td>2.7064</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>Non-Hispanic</td>\n",
       "      <td>17884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1290120 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Date    Area Gender   Race    Ethinicity  Wound\n",
       "0        2016-10-26  4.0000      M  White  Non-Hispanic      1\n",
       "1        2016-10-27  4.0000      M  White  Non-Hispanic      1\n",
       "2        2016-10-28  4.0000      M  White  Non-Hispanic      1\n",
       "3        2016-10-29  4.0000      M  White  Non-Hispanic      1\n",
       "4        2016-10-30  4.0000      M  White  Non-Hispanic      1\n",
       "...             ...     ...    ...    ...           ...    ...\n",
       "1290115  2023-01-05  2.7064      F  White  Non-Hispanic  17884\n",
       "1290116  2023-01-06  2.7064      F  White  Non-Hispanic  17884\n",
       "1290117  2023-01-07  2.7064      F  White  Non-Hispanic  17884\n",
       "1290118  2023-01-08  2.7064      F  White  Non-Hispanic  17884\n",
       "1290119  2023-01-09  2.7064      F  White  Non-Hispanic  17884\n",
       "\n",
       "[1290120 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_for=pd.read_csv(\"6_df_interpolated_for_forecasting_aug10.csv\")\n",
    "df_for=df_for.drop([\"Unnamed: 0\"],axis=1)\n",
    "df_for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95aeb9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_input_for_arima(df):    \n",
    "    #display(df)\n",
    "    df=df.reset_index()\n",
    "    total_n=df.shape[0]\n",
    "    n=math.ceil(0.15*total_n)\n",
    "    dff=pd.concat([df, df.tail(n), df.tail(n)]).drop_duplicates(keep=False)\n",
    "    #display(test)\n",
    "    #display(dff)\n",
    "    sample_row=dff.sample(1)\n",
    "    a=int(sample_row.index.values)\n",
    "    b=int(sample_row.index.values)+n\n",
    "    print(a)\n",
    "    print(b)\n",
    "    test=df[a:b]\n",
    "    train=pd.concat([df, test, test]).drop_duplicates(keep=False)\n",
    "    # #display(train)\n",
    "    return (test,train,a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc090c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_holtwinters(df, test, train):\n",
    "    #fit1 = sm.tsa.statespace.SARIMAX(train.Area, order=(2, 1, 4),seasonal_order=(0,1,1,7),initialization='approximate_diffuse').fit()\n",
    "    fit1 = ExponentialSmoothing(np.asarray(train['Area']) ,seasonal_periods=2 ,trend='add', seasonal='add').fit()\n",
    "\n",
    "    y_hat_avg = test.copy()\n",
    "    y_hat_avg['Holtwinters'] = fit1.forecast(len(test))\n",
    "    #print(y_hat_avg['ARIMA'])\n",
    "    plt.figure(figsize=(16,8))\n",
    "    #plt.plot( train['Area'], label='Train')\n",
    "    #plt.plot(test['Area'], label='Test')\n",
    "    plt.plot(df['Area'],label='Original')\n",
    "    plt.plot(y_hat_avg['Holtwinters'], label='Forecasted by Holtwinters')\n",
    "    plt.legend(loc='best')\n",
    "    #plt.axhline(0)\n",
    "    plt.grid()\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('Wound Area')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Accuracy measure of the model (to be done next)\n",
    "    forecast=y_hat_avg.Holtwinters\n",
    "    actual=test.Area\n",
    "    training_series=train.Area\n",
    "    testing_series=test.Area\n",
    "    prediction_series= y_hat_avg.Holtwinters\n",
    "\n",
    "\n",
    "\n",
    "    mape = np.mean(np.abs(forecast - actual)/np.abs(actual))  # MAPE\n",
    "    me = np.mean(forecast - actual)             # ME\n",
    "    mae = np.mean(np.abs(forecast - actual))    # MAE\n",
    "    mpe = np.mean((forecast - actual)/actual)   # MPE\n",
    "    rmse = np.mean((forecast - actual)**2)**.5  # RMSE\n",
    "     #as R-square value does not for forecasted value and actual value because forecasted values are 14 more than actual values, thus I am taking only the forecasted values minusing the last 14 values of the forecasted dataframe.\n",
    "    # df = df.iloc[:-2]\n",
    "    #forecast_without_last14=forecast.iloc[:-14]\n",
    "    #actual_without_nan=actual.dropna()\n",
    "    corr = np.corrcoef(forecast, actual)[0,1]   # corr\n",
    "    #corr= np.corrcoef(forecast_without_last14,actual_without_nan)[0,1]\n",
    "    r_square= corr**2\n",
    "    return (rmse, r_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e173e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_arima(test, train, df):\n",
    "\n",
    "    # Assuming you have your DataFrame 'df' containing 'ds', 'y', and other columns\n",
    "    # Sort the DataFrame by date\n",
    "    df['ds'] = pd.to_datetime(df['ds'])\n",
    "    df = df.sort_values('ds')\n",
    "\n",
    "    # Initialize the AutoARIMA model\n",
    "    arima_model = StatsForecast(\n",
    "        models=[AutoARIMA(season_length=7)],  # You can adjust the season_length as needed\n",
    "        freq='d'\n",
    "    )\n",
    "\n",
    "    # Initialize an empty DataFrame to store predictions\n",
    "    predictions = []\n",
    "\n",
    "    # Iterate over specific past dates for which you want predictions\n",
    "    #specific_dates = ['2019-03-11', '2019-03-12', '2019-03-13']  # Replace with your desired dates\n",
    "    specific_dates=test['ds'].values\n",
    "    for date in specific_dates:\n",
    "        # Filter data up to the specific date\n",
    "        train_data = df[df['ds'] <= date]\n",
    "        #train_data=train\n",
    "\n",
    "        # Fit the model using the filtered data\n",
    "        arima_model.fit(train_data)\n",
    "\n",
    "        # Predict using the model for the specific date\n",
    "        forecast_df = arima_model.predict(1)  # Predict one step (one day)\n",
    "\n",
    "        # Extract the predicted y value for the specific date\n",
    "        predicted_y = forecast_df['AutoARIMA'].values[0]\n",
    "\n",
    "        # Append the prediction to the predictions DataFrame\n",
    "        predictions.append({'ds': date, 'predicted_y': predicted_y})\n",
    "\n",
    "    # Print the predictions\n",
    "    #print(predictions)\n",
    "\n",
    "    y_hat_avg = test.copy()\n",
    "    y_hat_avg['ARIMA']=pd.DataFrame(predictions)['predicted_y'].values\n",
    "\n",
    "#     print(y_hat_avg['ARIMA'])\n",
    "    plt.figure(figsize=(16,8))\n",
    "    #plt.plot( train['y'], label='Train')\n",
    "    #plt.plot(test['y'], label='Test')\n",
    "    plt.plot(df['y'],label='Original')\n",
    "    plt.plot(y_hat_avg['ARIMA'], label='Forecasted by AutoARIMA')\n",
    "    plt.legend(loc='best')\n",
    "    #plt.axhline(0)\n",
    "    plt.grid()\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('Wound Area')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Accuracy measure of the model (to be done next)\n",
    "    forecast=y_hat_avg.ARIMA\n",
    "    actual=test.y\n",
    "    training_series=train.y\n",
    "    testing_series=test.y\n",
    "    prediction_series= y_hat_avg.ARIMA\n",
    "\n",
    "\n",
    "\n",
    "    mape = np.mean(np.abs(forecast - actual)/np.abs(actual))  # MAPE\n",
    "    me = np.mean(forecast - actual)             # ME\n",
    "    mae = np.mean(np.abs(forecast - actual))    # MAE\n",
    "    mpe = np.mean((forecast - actual)/actual)   # MPE\n",
    "    rmse = np.mean((forecast - actual)**2)**.5  # RMSE\n",
    "     #as R-square value does not for forecasted value and actual value because forecasted values are 14 more than actual values, thus I am taking only the forecasted values minusing the last 14 values of the forecasted dataframe.\n",
    "    # df = df.iloc[:-2]\n",
    "    forecast_without_last14=forecast.iloc[:-14]\n",
    "    actual_without_nan=actual.dropna()\n",
    "    corr = np.corrcoef(forecast, actual)[0,1]   # corr\n",
    "    #corr= np.corrcoef(forecast_without_last14,actual_without_nan)[0,1]\n",
    "    r_square= corr**2\n",
    "    return (rmse, r_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e07a5247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_arima(df, test, train):\n",
    "    # Assuming you have your DataFrame 'df' containing 'ds', 'y', and other columns\n",
    "    # Sort the DataFrame by date\n",
    "    df['ds'] = pd.to_datetime(df['ds'])\n",
    "    df = df.sort_values('ds')\n",
    "\n",
    "    # Initialize the AutoARIMA model\n",
    "    arima_model = StatsForecast(\n",
    "        models=[AutoARIMA(season_length=7)],  # You can adjust the season_length as needed\n",
    "        freq='d'\n",
    "    )\n",
    "\n",
    "    # Initialize an empty DataFrame to store predictions\n",
    "    predictions = []\n",
    "\n",
    "    # Iterate over specific past dates for which you want predictions\n",
    "    #specific_dates = ['2019-03-11', '2019-03-12', '2019-03-13']  # Replace with your desired dates\n",
    "    specific_dates=test['ds'].values\n",
    "    for date in specific_dates:\n",
    "        # Filter data up to the specific date\n",
    "        train_data = df[df['ds'] <= date]\n",
    "        #train_data=train\n",
    "\n",
    "        # Fit the model using the filtered data\n",
    "        arima_model.fit(train_data)\n",
    "\n",
    "        # Predict using the model for the specific date\n",
    "        forecast_df = arima_model.predict(1)  # Predict one step (one day)\n",
    "\n",
    "        # Extract the predicted y value for the specific date\n",
    "        predicted_y = forecast_df['AutoARIMA'].values[0]\n",
    "\n",
    "        # Append the prediction to the predictions DataFrame\n",
    "        predictions.append({'ds': date, 'predicted_y': predicted_y})\n",
    "\n",
    "    # Print the predictions\n",
    "    #print(predictions)\n",
    "\n",
    "    y_hat_avg = test.copy()\n",
    "    y_hat_avg['ARIMA']=pd.DataFrame(predictions)['predicted_y'].values\n",
    "\n",
    "    #     print(y_hat_avg['ARIMA'])\n",
    "    plt.figure(figsize=(16,8))\n",
    "    #plt.plot( train['y'], label='Train')\n",
    "    #plt.plot(test['y'], label='Test')\n",
    "    plt.plot(df['y'],label='Original')\n",
    "    plt.plot(y_hat_avg['ARIMA'], label='Forecasted by AutoARIMA')\n",
    "    plt.legend(loc='best')\n",
    "    #plt.axhline(0)\n",
    "    plt.grid()\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('Wound Area')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Accuracy measure of the model (to be done next)\n",
    "    forecast=y_hat_avg.ARIMA\n",
    "    actual=test.y\n",
    "    training_series=train.y\n",
    "    testing_series=test.y\n",
    "    prediction_series= y_hat_avg.ARIMA\n",
    "\n",
    "\n",
    "\n",
    "    mape = np.mean(np.abs(forecast - actual)/np.abs(actual))  # MAPE\n",
    "    me = np.mean(forecast - actual)             # ME\n",
    "    mae = np.mean(np.abs(forecast - actual))    # MAE\n",
    "    mpe = np.mean((forecast - actual)/actual)   # MPE\n",
    "    rmse = np.mean((forecast - actual)**2)**.5  # RMSE\n",
    "    # df = df.iloc[:-2]\n",
    "    forecast_without_last14=forecast.iloc[:-14]\n",
    "    actual_without_nan=actual.dropna()\n",
    "    corr = np.corrcoef(forecast, actual)[0,1]   # corr\n",
    "    r_square= corr**2\n",
    "    return (rmse, r_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39b02899",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_prophet(df, test, train):\n",
    "    # prepare expected column names\n",
    "    dff=df\n",
    "    dff.columns = ['ds', 'y']\n",
    "    dff['ds']= to_datetime(dff['ds'])\n",
    "    # define the model\n",
    "    model = Prophet(daily_seasonality=True)\n",
    "    #model=Prophet()\n",
    "    # fit the model\n",
    "    model.fit(dff)\n",
    "\n",
    "    #print(test.Date.iloc[0])\n",
    "\n",
    "    # define the period for which we want a prediction\n",
    "    future = []\n",
    "    for j in range(0, len(test)):\n",
    "        date = test.ds.iloc[j]\n",
    "        future.append([date])\n",
    "    future = pd.DataFrame(future)\n",
    "    future.columns = ['ds']\n",
    "    future['ds']= to_datetime(future['ds'])\n",
    "    # use the model to make a forecast\n",
    "    forecast = model.predict(future)\n",
    "    \n",
    "    y_hat_avg = test.copy()\n",
    "    y_hat_avg['Prophet']=pd.DataFrame(forecast)['yhat'].values\n",
    "    \n",
    "    plt.figure(figsize=(16,8))\n",
    "    #plt.plot( train['y'], label='Train')\n",
    "    #plt.plot(test['y'], label='Test')\n",
    "    plt.plot(df['y'],label='Original')\n",
    "    plt.plot(y_hat_avg['Prophet'], label='Forecasted by Prophet')\n",
    "    plt.legend(loc='best')\n",
    "    #plt.axhline(0)\n",
    "    plt.grid()\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('Wound Area')\n",
    "    \n",
    "    pyplot.show()\n",
    "\n",
    "    #Accuracy measure of Prophet\n",
    "    forecastP=forecast.yhat\n",
    "    actual=test.y\n",
    "    training_series=train.y\n",
    "    testing_series=test.y\n",
    "    prediction_series= forecast.yhat\n",
    "\n",
    "    forecastPP=forecastP.reset_index()\n",
    "    actualPP=actual.reset_index()\n",
    "    training_seriesPP=training_series.reset_index()\n",
    "    testing_seriesPP=testing_series.reset_index()\n",
    "    prediction_seriesPP=prediction_series.reset_index()\n",
    "    rmse = np.mean((forecastPP.yhat - actualPP.y)**2)**.5  # RMSE\n",
    "    corr= np.corrcoef(forecastPP.yhat,actualPP.y)[0,1]     #corr\n",
    "    r_square= corr**2  \n",
    "    \n",
    "    return (rmse, r_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "154db67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_LSTM(df,random_number_start,random_number_end):\n",
    "    # Load and preprocess your DataFrame\n",
    "    data = df  # Load your DataFrame\n",
    "    data['Date'] = pd.to_datetime(data['Date'])  # Convert 'Date' column to datetime\n",
    "    dataframe=df.copy()\n",
    "    \n",
    "    # Normalize the 'Area' values\n",
    "    scaler = MinMaxScaler()\n",
    "    data['Area'] = scaler.fit_transform(data['Area'].values.reshape(-1, 1))\n",
    "\n",
    "    # Create sequences and target values\n",
    "    sequence_length = 1  # Adjust as needed\n",
    "    sequences = []\n",
    "    target_values = []\n",
    "\n",
    "#     random_number_start=random.randint(0,data.shape[0]-int(0.20*data.shape[0]))\n",
    "#     random_number_end=random_number_start+int(0.20*data.shape[0])\n",
    "\n",
    "    data_test=data[random_number_start:random_number_end]\n",
    "    remove_index=list(data_test.index.values)\n",
    "    data_train=data.drop(remove_index,axis=0)\n",
    "\n",
    "    # Make train dataset\n",
    "    for i in range(len(data_train) - sequence_length):\n",
    "        sequences.append(data_train['Area'].values[i:i+sequence_length])\n",
    "        target_values.append(data_train['Area'].values[i+sequence_length])\n",
    "\n",
    "    X_train = np.array(sequences)\n",
    "    y_train = np.array(target_values)\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "    # Make test dataset\n",
    "    sequences = []\n",
    "    target_values = []\n",
    "    for i in range(len(data_test) - sequence_length):\n",
    "        sequences.append(data_test['Area'].values[i:i+sequence_length])\n",
    "        target_values.append(data_test['Area'].values[i+sequence_length])\n",
    "\n",
    "    X_test = np.array(sequences)\n",
    "    y_test = np.array(target_values)\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    # Build the LSTM model\n",
    "    model = Sequential()\n",
    "    #units=int(df.shape[0])\n",
    "    \n",
    "    \n",
    "    model.add(LSTM(50, activation='relu', input_shape=(sequence_length, 1), return_sequences=True))\n",
    "    \n",
    "#     if df.shape[0]<40:\n",
    "#         model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "#         model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "#         model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "#         print(\"Number of total LSTM Blocks:\",5)\n",
    "    \n",
    "#     else:\n",
    "#         for k in range(0, int(df.shape[0]/20)-2):\n",
    "#             model.add(LSTM(50, activation='relu', return_sequences=True))\n",
    "#         print(\"Number of total LSTM Blocks:\",k+3)\n",
    "\n",
    "    model.add(LSTM(50, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse',metrics=tf.metrics.MeanAbsoluteError())\n",
    "\n",
    "    print(\"Total number of visit days after interpolation\",df.shape[0])\n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=16,verbose=0)\n",
    "\n",
    "    # Make predictions on the entire dataset\n",
    "    predicted_values_test = model.predict(X_test)\n",
    "    predicted_values_train = model.predict(X_train)\n",
    "\n",
    "    # Inverse transform predictions and target values\n",
    "    predicted_values_test = scaler.inverse_transform(predicted_values_test)\n",
    "    predicted_values_train = scaler.inverse_transform(predicted_values_train)\n",
    "    y_train_original = scaler.inverse_transform(y_train.reshape(-1, 1)).flatten()\n",
    "    y_test_original = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Create arrays for plotting the entire time series\n",
    "    train_dates = data_train['Date'].iloc[:-sequence_length]\n",
    "    test_dates = data_test['Date'].iloc[:-sequence_length]\n",
    "    all_dates=dataframe['Date'].iloc[:-sequence_length]\n",
    "    all_values=dataframe['Area'].iloc[:-sequence_length]\n",
    "    \n",
    "    #appended_series_date = train_dates.append(test_dates, ignore_index=True)\n",
    "    #appended_series_area = y_train_original.append(y_test_original, ignore_index=True)\n",
    "\n",
    "\n",
    "    # Plot the entire time series data: train, test, and predicted values\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    #plt.plot(train_dates, y_train_original, label='Train Actual')\n",
    "    #plt.plot(test_dates, y_test_original, label='Test Actual')\n",
    "    plt.plot(all_dates.index,all_values,label='Original')\n",
    "    plt.plot(test_dates.index, predicted_values_test, label='Forecasted by LSTM')\n",
    "    plt.xlabel('Days')\n",
    "    plt.ylabel('Area Value')\n",
    "    #plt.title('Time Series Forecasting with LSTM')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    actual=y_test_original\n",
    "    forecast=predicted_values_test\n",
    "    \n",
    "#     print(actual)\n",
    "#     print(forecast.flatten())\n",
    "\n",
    "    corr= np.corrcoef(actual,forecast.flatten())[0,1]\n",
    "    r_square= corr**2  #r_square\n",
    "\n",
    "    #print(\"R-square:\",r_square)\n",
    "\n",
    "    y_hat_avg = pd.DataFrame(y_test).copy()\n",
    "    y_hat_avg['LSTM']=pd.DataFrame(forecast)[0].values\n",
    "\n",
    "\n",
    "    training_series=pd.DataFrame(y_train)[0]\n",
    "    testing_series=pd.DataFrame(y_test)[0]\n",
    "    prediction_series= y_hat_avg.LSTM\n",
    "\n",
    "    rmse = np.mean((forecast - actual)**2)**.5  # RMSE\n",
    "    return (rmse, r_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ad6d9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Bidirectional\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "def model_BiLSTM(df,random_number_start,random_number_end):\n",
    "    # Load and preprocess your DataFrame\n",
    "    data = df  # Load your DataFrame\n",
    "    data['Date'] = pd.to_datetime(data['Date'])  # Convert 'Date' column to datetime\n",
    "    dataframe=df.copy()\n",
    "\n",
    "    # Normalize the 'Area' values\n",
    "    scaler = MinMaxScaler()\n",
    "    data['Area'] = scaler.fit_transform(data['Area'].values.reshape(-1, 1))\n",
    "\n",
    "    # Create sequences and target values\n",
    "    sequence_length = 1  # Adjust as needed\n",
    "    sequences = []\n",
    "    target_values = []\n",
    "\n",
    "#     random_number_start = random.randint(0, data.shape[0] - int(0.20 * data.shape[0]))\n",
    "#     random_number_end = random_number_start + int(0.20 * data.shape[0])\n",
    "\n",
    "    data_test = data[random_number_start:random_number_end]\n",
    "    remove_index = list(data_test.index.values)\n",
    "    data_train = data.drop(remove_index, axis=0)\n",
    "\n",
    "    # Make train dataset\n",
    "    for i in range(len(data_train) - sequence_length):\n",
    "        sequences.append(data_train['Area'].values[i:i + sequence_length])\n",
    "        target_values.append(data_train['Area'].values[i + sequence_length])\n",
    "\n",
    "    X_train = np.array(sequences)\n",
    "    y_train = np.array(target_values)\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "    # Make test dataset\n",
    "    sequences = []\n",
    "    target_values = []\n",
    "    for i in range(len(data_test) - sequence_length):\n",
    "        sequences.append(data_test['Area'].values[i:i + sequence_length])\n",
    "        target_values.append(data_test['Area'].values[i + sequence_length])\n",
    "\n",
    "    X_test = np.array(sequences)\n",
    "    y_test = np.array(target_values)\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    # Build the BiLSTM model\n",
    "    model = Sequential()\n",
    "    forward_layer = LSTM(50, return_sequences=True)\n",
    "    backward_layer = LSTM(50, activation='relu', return_sequences=True,go_backwards=True)\n",
    "    model.add(Bidirectional(forward_layer, backward_layer=backward_layer,input_shape=(sequence_length, 1)))\n",
    "\n",
    "    #model.add(Bidirectional(LSTM(50, activation='relu'), input_shape=(sequence_length, 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "    print(\"Total number of visit days after interpolation\", df.shape[0])\n",
    "    # Train the model on the training data\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=16, verbose=0)\n",
    "\n",
    "    # Make predictions on the entire dataset\n",
    "    predicted_values_test = model.predict(X_test)\n",
    "    #predicted_values_test=float(predicted_values_test)\n",
    "    #predicted_values_train = model.predict(X_train)\n",
    "\n",
    "\n",
    "    # Reshape predicted_values_test to 2D\n",
    "    predicted_values_test_2d = predicted_values_test.reshape(-1, 1)\n",
    "\n",
    "    #predicted_values_test_2d=predicted_values_test_2d.flatten()\n",
    "    # Perform inverse transformation\n",
    "    predicted_values_test_inverse = scaler.inverse_transform(predicted_values_test_2d)#.flatten()\n",
    "\n",
    "    # Inverse transform predictions and target values\n",
    "    #predicted_values_test = scaler.inverse_transform(predicted_values_test)\n",
    "    #predicted_values_train = scaler.inverse_transform(predicted_values_train)\n",
    "    y_train_original = scaler.inverse_transform(y_train.reshape(-1, 1)).flatten()\n",
    "    y_test_original = scaler.inverse_transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "    # Create arrays for plotting the entire time series\n",
    "    train_dates = data_train['Date'].iloc[:-sequence_length]\n",
    "    test_dates = data_test['Date'].iloc[:-sequence_length]\n",
    "    all_dates=dataframe['Date'].iloc[:-sequence_length]\n",
    "    all_values=dataframe['Area'].iloc[:-sequence_length]\n",
    "    \n",
    "    # Plot the entire time series data: train, test, and predicted values\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    #plt.plot(train_dates, y_train_original, label='Train Actual')\n",
    "    #plt.plot(test_dates, y_test_original, label='Test Actual')\n",
    "    plt.plot(all_dates,all_values,label='Original')\n",
    "    print(\"test_dates shape:\" ,test_dates.shape)    \n",
    "    print(\"predicted_values_test_inverse shape:\" ,predicted_values_test_inverse.shape)\n",
    "    plt.plot(test_dates, predicted_values_test_inverse, label='Forecasted by BiLSTM')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Area Value')\n",
    "    #plt.title('Time Series Forecasting with BiLSTM')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    actual = y_test_original\n",
    "    forecast = predicted_values_test_inverse\n",
    "    \n",
    "    corr= np.corrcoef(actual,forecast.flatten())[0,1]\n",
    "    r_square= corr**2  #r_square\n",
    "\n",
    "\n",
    "    y_hat_avg = pd.DataFrame(y_test).copy()\n",
    "    y_hat_avg['BiLSTM'] = pd.DataFrame(forecast)[0].values\n",
    "\n",
    "    training_series = pd.DataFrame(y_train)[0]\n",
    "    testing_series = pd.DataFrame(y_test)[0]\n",
    "    prediction_series = y_hat_avg.BiLSTM\n",
    "\n",
    "    rmse = np.mean((forecast - actual)**2)**.5  # RMSE\n",
    "    return rmse, r_square"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb6f34f",
   "metadata": {},
   "source": [
    "## Counting the number of wounds from patients from different categories and running Prophet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6cc880",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_wounds=df_for[\"Wound\"].unique()\n",
    "\n",
    "result_df=pd.DataFrame(index=np.arange(len(list_wounds)))\n",
    "\n",
    "result_df[\"Wound\"]=np.nan\n",
    "result_df[\"Gender\"]=np.nan\n",
    "result_df[\"Race\"]=np.nan\n",
    "result_df[\"Ethinicity\"]=np.nan\n",
    "\n",
    "result_df[\"RMSE_Holtwinters\"]=np.nan\n",
    "result_df[\"R-squared_Holtwinters\"]=np.nan\n",
    "\n",
    "result_df[\"RMSE_AutoARIMA\"]=np.nan\n",
    "result_df[\"R-squared_AutoARIMA\"]=np.nan\n",
    "\n",
    "result_df[\"RMSE_Prophet\"]=np.nan\n",
    "result_df[\"R-squared_Prophet\"]=np.nan\n",
    "\n",
    "result_df[\"RMSE_LSTM\"]=np.nan\n",
    "result_df[\"R-squared_LSTM\"]=np.nan\n",
    "\n",
    "result_df[\"RMSE_BiLSTM\"]=np.nan\n",
    "result_df[\"R-squared_BiLSTM\"]=np.nan\n",
    "    \n",
    "\n",
    "for i in range(0, len(list_wounds)):\n",
    "    print(\"Done\", i/len(list_wounds)*100,\"%\")\n",
    "#     if i>4:\n",
    "#         break\n",
    "    print(\"Wound:\",i+1)\n",
    "    wound=list_wounds[i]\n",
    "    df_1=df_for.query(\"Wound==@wound\")\n",
    "    #display(df_1)\n",
    "    df=df_1[[\"Date\",\"Area\"]]\n",
    "    test,train,random_number_start, random_number_end=make_input_for_arima(df)\n",
    "\n",
    "\n",
    "    result_df[\"Wound\"][i]=int(df_1[\"Wound\"].unique()[0])\n",
    "    result_df[\"Gender\"][i]=str(df_1[\"Gender\"].unique()[0])\n",
    "    result_df[\"Race\"][i]=str(df_1[\"Race\"].unique()[0])\n",
    "    result_df[\"Ethinicity\"][i]=str(df_1[\"Ethinicity\"].unique()[0])\n",
    "\n",
    "    df=df.reset_index()\n",
    "    df=df.drop([\"index\"],axis=1)\n",
    "\n",
    "\n",
    "    if df.shape[0]>9 and df.shape[0]<1200:\n",
    "\n",
    "                #Holt winters\n",
    "                rmse_h, r_square_h=model_holtwinters(df, test, train)\n",
    "                result_df[\"RMSE_Holtwinters\"][i]=rmse_h\n",
    "                result_df[\"R-squared_Holtwinters\"][i]=r_square_h\n",
    "            \n",
    "                #Auto ARIMA\n",
    "                df = df.rename(columns={'Date': 'ds', 'Area': 'y'})\n",
    "                test = test.rename(columns={'Date': 'ds', 'Area': 'y'})\n",
    "                train = train.rename(columns={'Date': 'ds', 'Area': 'y'})\n",
    "                test=test.drop(['index'],axis=1)\n",
    "                train=train.drop(['index'],axis=1)\n",
    "                df['unique_id']='unique_wound'\n",
    "                test['unique_id']='unique_wound'\n",
    "                train['unique_id']='unique_wound'\n",
    "                df=df.reset_index()\n",
    "                df=df.drop(['index'],axis=1)\n",
    "                rmse_a, r_square_a=model_arima(df, test, train)\n",
    "                result_df[\"RMSE_AutoARIMA\"][i]=rmse_a\n",
    "                result_df[\"R-squared_AutoARIMA\"][i]=r_square_a\n",
    "                \n",
    "                #Prophet\n",
    "                df=df.drop([\"unique_id\"],axis=1)\n",
    "                test=test.drop([\"unique_id\"],axis=1)\n",
    "                train=train.drop([\"unique_id\"],axis=1)\n",
    "                rmse_p, r_square_p=model_prophet(df, test, train)\n",
    "                result_df[\"RMSE_Prophet\"][i]=rmse_p\n",
    "                result_df[\"R-squared_Prophet\"][i]=r_square_p\n",
    "                \n",
    "                #LSTM\n",
    "                df=df_1[[\"Date\",\"Area\"]]\n",
    "                df=df.reset_index()\n",
    "                df=df.drop([\"index\"],axis=1)\n",
    "                rmse_l, r_square_l=model_LSTM(df, random_number_start,random_number_end)\n",
    "                result_df[\"RMSE_LSTM\"][i]=rmse_l\n",
    "                result_df[\"R-squared_LSTM\"][i]=r_square_l\n",
    "                \n",
    "                #BiLSTM\n",
    "                rmse_b, r_square_b=model_BiLSTM(df, random_number_start,random_number_end)\n",
    "                result_df[\"RMSE_BiLSTM\"][i]=rmse_b\n",
    "                result_df[\"R-squared_BiLSTM\"][i]=r_square_b\n",
    "\n",
    "\n",
    "result_df[\"Wound\"]=result_df[\"Wound\"].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0620a45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4ddd122d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6995e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=result_df.dropna(how='all')\n",
    "#result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0ff2fe52",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.drop(result_df.tail(1).index,inplace=True)\n",
    "#result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e510ab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df_prev=pd.read_csv(\"final_updated_result.csv\")\n",
    "result_df_prev=result_df_prev.drop([\"Unnamed: 0\"],axis=1)\n",
    "result_df_prev=result_df_prev.dropna(how='all')\n",
    "result_df_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "03022e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#result_df_prev.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c66cc064",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=pd.concat([result_df_prev,result_df],axis=0)\n",
    "#new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c26e2ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_df.to_csv(\"final_updated_result.csv\")\n",
    "new_df.to_csv(\"accuracy_metrics_forecasting_models.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9766ae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics=pd.read_csv(\"accuracy_metrics_forecasting_models.csv\")\n",
    "metrics=metrics.drop([\"Unnamed: 0\"],axis=1)\n",
    "metrics.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6105420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
